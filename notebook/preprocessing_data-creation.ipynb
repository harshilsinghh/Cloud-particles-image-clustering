{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08fba6bd-1030-4d78-a054-1751b4c4fdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 18252 particles from 574 images.\n",
      "All particle data saved to: particles.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# === Settings ===\n",
    "input_folder = 'combined_images'  # <--- change this\n",
    "output_folder = 'particles_output'\n",
    "output_csv = 'particles.csv'\n",
    "output_size = (64, 64)\n",
    "min_width = 35\n",
    "min_height = 35\n",
    "bbox_padding = 1\n",
    "upscale = 5\n",
    "\n",
    "# Create output dir\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Sharpening kernel\n",
    "sharpen_kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5, -1],\n",
    "                           [0, -1, 0]])\n",
    "\n",
    "# Load all image paths\n",
    "image_paths = glob(os.path.join(input_folder, '*'))\n",
    "\n",
    "# To store all flattened particle data\n",
    "all_particle_data = []\n",
    "particle_index = 0\n",
    "\n",
    "# === Process each image ===\n",
    "for img_path in image_paths:\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"Skipping {img_path} (not a valid image)\")\n",
    "        continue\n",
    "\n",
    "    img_height, img_width = image.shape[:2]\n",
    "\n",
    "    # HSV blue mask\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([110, 180, 80])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        if w < min_width or h < min_height:\n",
    "            continue\n",
    "\n",
    "        # Apply 1-px padding\n",
    "        x_pad = max(x - bbox_padding, 0)\n",
    "        y_pad = max(y - bbox_padding, 0)\n",
    "        x_end = min(x + w + bbox_padding, img_width)\n",
    "        y_end = min(y + h + bbox_padding, img_height)\n",
    "\n",
    "        # Crop and enlarge\n",
    "        particle = image[y_pad:y_end, x_pad:x_end]\n",
    "        enlarged = cv2.resize(particle,\n",
    "                              ((x_end - x_pad) * upscale, (y_end - y_pad) * upscale),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Grayscale and sharpen\n",
    "        gray = cv2.cvtColor(enlarged, cv2.COLOR_BGR2GRAY)\n",
    "        sharpened = cv2.filter2D(gray, -1, sharpen_kernel)\n",
    "\n",
    "        # Resize while keeping aspect ratio\n",
    "        h_i, w_i = sharpened.shape\n",
    "        scale = min(output_size[0] / h_i, output_size[1] / w_i)\n",
    "        new_w, new_h = int(w_i * scale), int(h_i * scale)\n",
    "        resized = cv2.resize(sharpened, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Pad to 64x64 with white background\n",
    "        padded = np.full(output_size, 255, dtype=np.uint8)\n",
    "        x_offset = (output_size[1] - new_w) // 2\n",
    "        y_offset = (output_size[0] - new_h) // 2\n",
    "        padded[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized\n",
    "\n",
    "        # Save particle image\n",
    "        out_path = os.path.join(output_folder, f\"particle_{particle_index:04d}.png\")\n",
    "        cv2.imwrite(out_path, padded)\n",
    "\n",
    "        # Add to dataset\n",
    "        all_particle_data.append(padded.flatten())\n",
    "        particle_index += 1\n",
    "\n",
    "print(f\"Extracted {particle_index} particles from {len(image_paths)} images.\")\n",
    "\n",
    "# Save final CSV\n",
    "all_particle_array = np.array(all_particle_data)\n",
    "np.savetxt(output_csv, all_particle_array, fmt='%d', delimiter=',')\n",
    "\n",
    "print(f\"All particle data saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6e361-4650-4e7c-8864-925275eb4a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
